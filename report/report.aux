\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\tcolorbox@label[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{RefWorks:12}
\citation{RefWorks:10}
\citation{RefWorks:2}
\citation{RefWorks:1}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{10}{section.3}}
\@writefile{brf}{\backcite{RefWorks:12}{{10}{1}{section.3}}}
\@writefile{brf}{\backcite{RefWorks:10}{{10}{1}{section.3}}}
\@writefile{brf}{\backcite{RefWorks:2}{{10}{1}{section.3}}}
\@writefile{brf}{\backcite{RefWorks:1}{{10}{1}{section.3}}}
\citation{RefWorks:13}
\citation{RefWorks:10}
\citation{RefWorks:12}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{11}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Facial Expressions}{11}{subsection.5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Facial Action Coding System (FACS)}{11}{subsubsection.6}}
\@writefile{brf}{\backcite{RefWorks:13}{{11}{2.1.1}{subsubsection.6}}}
\@writefile{brf}{\backcite{RefWorks:10}{{11}{2.1.1}{subsubsection.6}}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Interpreting emotions}{11}{subsubsection.10}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.1.2.1}Discrete case}{11}{paragraph.11}}
\@writefile{brf}{\backcite{RefWorks:12}{{11}{2.1.2.1}{paragraph.11}}}
\citation{RefWorks:2}
\citation{RefWorks:18,RefWorks:19}
\citation{RefWorks:2}
\citation{RefWorks:1}
\citation{RefWorks:1}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The scale for measuring the intensity with which an AU is activated\relax }}{12}{table.caption.7}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:scale-au}{{1}{12}{The scale for measuring the intensity with which an AU is activated\relax }{table.caption.7}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.1.2.2}Continuous case}{12}{paragraph.12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Facial Expression Analysis}{12}{subsection.15}}
\@writefile{brf}{\backcite{RefWorks:2}{{12}{2.2}{subsection.15}}}
\@writefile{brf}{\backcite{RefWorks:18}{{12}{2.2}{subsection.15}}}
\@writefile{brf}{\backcite{RefWorks:19}{{12}{2.2}{subsection.15}}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Facial Action Units\relax }}{13}{figure.caption.8}}
\newlabel{fig:fau}{{1}{13}{Facial Action Units\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Database - EmotioNet}{13}{subsection.16}}
\newlabel{sec:databases}{{2.3}{13}{Database - EmotioNet}{subsection.16}{}}
\@writefile{brf}{\backcite{RefWorks:2}{{13}{2.3}{subsection.16}}}
\@writefile{brf}{\backcite{RefWorks:1}{{13}{2.3}{subsection.16}}}
\@writefile{brf}{\backcite{RefWorks:1}{{13}{2.3}{subsection.16}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The neutral-onset-apex-offset-neutral cycle of an action unit activation\relax }}{14}{figure.caption.9}}
\newlabel{fig:onset}{{2}{14}{The neutral-onset-apex-offset-neutral cycle of an action unit activation\relax }{figure.caption.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces The 6 basic emotions (plus neutral) and the corresponding Action Units that are generally activate when the emotion is present\relax }}{14}{table.caption.14}}
\newlabel{tab:emo-au}{{2}{14}{The 6 basic emotions (plus neutral) and the corresponding Action Units that are generally activate when the emotion is present\relax }{table.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Deep Learning}{14}{subsection.18}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Plotting emotions according to their valence and arousal\relax }}{15}{figure.caption.13}}
\newlabel{fig:arval}{{3}{15}{Plotting emotions according to their valence and arousal\relax }{figure.caption.13}{}}
\newlabel{eq:NN}{{2}{15}{Deep Learning}{equation.20}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Deep Convolutional Neural Networks}{15}{subsubsection.21}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Example image from the EmotioNet database. Only two AUs, 6 and 12, are labelled as active (i.e. '1'). AUs 1, 2, 4, 5, 9, 17, 20, 25, and 26 are labelled as inactive and the remaining AUs are labelled as occluded or '999'\relax }}{16}{figure.caption.17}}
\newlabel{fig:emotionet_example}{{4}{16}{Example image from the EmotioNet database. Only two AUs, 6 and 12, are labelled as active (i.e. '1'). AUs 1, 2, 4, 5, 9, 17, 20, 25, and 26 are labelled as inactive and the remaining AUs are labelled as occluded or '999'\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces example of a DCNN architecture with a succession of convolutional + max pooling layers followed by a bloc of fully connected layers\relax }}{16}{figure.caption.22}}
\newlabel{fig:cnn}{{5}{16}{example of a DCNN architecture with a succession of convolutional + max pooling layers followed by a bloc of fully connected layers\relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.4.1.1}Convolutional Layers}{16}{paragraph.23}}
\newlabel{eq:convolution}{{3}{17}{Convolutional Layers}{equation.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Example of a convolution operation at a single spatial location. The large yellow square represents the kernel filter. Note that no padding has been applied here which is why the convolved feature (i.e. the response map) is smaller.\relax }}{18}{figure.caption.27}}
\newlabel{fig:conv_op}{{6}{18}{Example of a convolution operation at a single spatial location. The large yellow square represents the kernel filter. Note that no padding has been applied here which is why the convolved feature (i.e. the response map) is smaller.\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.4.1.2}Pooling Layers}{18}{paragraph.28}}
\citation{RefWorks:22}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces example of a single max pooling operation with a $2 \times 2$ pooling filter and a stride of 2\relax }}{19}{figure.caption.29}}
\newlabel{fig:maxpool}{{7}{19}{example of a single max pooling operation with a $2 \times 2$ pooling filter and a stride of 2\relax }{figure.caption.29}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.4.1.3}Fully Connected Layers}{19}{paragraph.32}}
\citation{RefWorks:23}
\@writefile{brf}{\backcite{RefWorks:22}{{20}{2.4.1.3}{paragraph.32}}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.4.1.4}Dropout Layers}{20}{paragraph.33}}
\@writefile{brf}{\backcite{RefWorks:23}{{20}{2.4.1.4}{paragraph.33}}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces example dropout layers: the crossed neurons are blocked from sending their inputs to the next layer\relax }}{20}{figure.caption.34}}
\newlabel{fig:dropout}{{8}{20}{example dropout layers: the crossed neurons are blocked from sending their inputs to the next layer\relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}Activation functions}{20}{subsubsection.35}}
\newlabel{sec:activation_functions}{{2.4.2}{20}{Activation functions}{subsubsection.35}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.4.2.1}Sigmoid}{21}{paragraph.36}}
\newlabel{para:sigmoid}{{2.4.2.1}{21}{Sigmoid}{paragraph.36}{}}
\newlabel{eq:sigmoid}{{4}{21}{Sigmoid}{equation.37}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.4.2.2}Softmax}{21}{paragraph.38}}
\newlabel{para:softmax}{{2.4.2.2}{21}{Softmax}{paragraph.38}{}}
\newlabel{eq:softmax}{{5}{21}{Softmax}{equation.39}{}}
\citation{RefWorks:24}
\citation{RefWorks:25}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.4.2.3}ReLU}{22}{paragraph.40}}
\newlabel{para:relu}{{2.4.2.3}{22}{ReLU}{paragraph.40}{}}
\@writefile{brf}{\backcite{RefWorks:24}{{22}{2.4.2.3}{paragraph.40}}}
\newlabel{eq:relu}{{6}{22}{ReLU}{equation.41}{}}
\@writefile{brf}{\backcite{RefWorks:25}{{22}{2.4.2.3}{equation.41}}}
\newlabel{eq:leaky_relu}{{7}{22}{ReLU}{equation.42}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.3}Loss functions}{22}{subsubsection.43}}
\newlabel{sec:loss}{{2.4.3}{22}{Loss functions}{subsubsection.43}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.4.3.1}Mean Squared Error}{23}{paragraph.44}}
\newlabel{para:mse}{{2.4.3.1}{23}{Mean Squared Error}{paragraph.44}{}}
\newlabel{eq:mse}{{8}{23}{Mean Squared Error}{equation.45}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.4.3.2}Cross Entropy}{23}{paragraph.46}}
\newlabel{para:cross_entropy}{{2.4.3.2}{23}{Cross Entropy}{paragraph.46}{}}
\newlabel{eq:cross_entropy}{{9}{23}{Cross Entropy}{equation.47}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.4}Optimisers}{23}{subsubsection.48}}
\newlabel{sec:optimisers}{{2.4.4}{23}{Optimisers}{subsubsection.48}{}}
\newlabel{eq:grad_descent}{{10}{24}{Optimisers}{equation.49}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.4.4.1}Stochastic Gradient Descent}{24}{paragraph.50}}
\newlabel{para:sgd}{{2.4.4.1}{24}{Stochastic Gradient Descent}{paragraph.50}{}}
\newlabel{eq:sgd}{{11}{24}{Stochastic Gradient Descent}{equation.51}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.4.4.2}SGD with Momentum}{24}{paragraph.52}}
\newlabel{para:sgd_momentum}{{2.4.4.2}{24}{SGD with Momentum}{paragraph.52}{}}
\citation{RefWorks:26}
\newlabel{eq:sgd_momentum}{{13}{25}{SGD with Momentum}{equation.54}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.4.4.3}Adagrad}{25}{paragraph.55}}
\newlabel{para:adagrad}{{2.4.4.3}{25}{Adagrad}{paragraph.55}{}}
\@writefile{brf}{\backcite{RefWorks:26}{{25}{2.4.4.3}{paragraph.55}}}
\newlabel{eq:adagrad_cache}{{14}{25}{Adagrad}{equation.56}{}}
\citation{RefWorks:2}
\citation{RefWorks:22}
\citation{RefWorks:28}
\citation{RefWorks:1}
\newlabel{eq:adagrad}{{15}{26}{Adagrad}{equation.57}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.4.4.4}RMSProp}{26}{paragraph.58}}
\newlabel{para:rmsprop}{{2.4.4.4}{26}{RMSProp}{paragraph.58}{}}
\newlabel{eq:rmsprop}{{16}{26}{RMSProp}{equation.59}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.5}Models}{26}{subsubsection.60}}
\newlabel{sec:models}{{2.4.5}{26}{Models}{subsubsection.60}{}}
\@writefile{brf}{\backcite{RefWorks:2}{{26}{2.4.5}{subsubsection.60}}}
\@writefile{brf}{\backcite{RefWorks:22}{{26}{2.4.5}{subsubsection.60}}}
\@writefile{brf}{\backcite{RefWorks:28}{{26}{2.4.5}{subsubsection.60}}}
\@writefile{brf}{\backcite{RefWorks:1}{{26}{2.4.5}{subsubsection.60}}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.4.5.1}VGG 16}{26}{paragraph.61}}
\newlabel{para:vgg16}{{2.4.5.1}{26}{VGG 16}{paragraph.61}{}}
\citation{RefWorks:30}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces structure of the VGG 16 deep convolutional network\relax }}{27}{figure.caption.62}}
\newlabel{fig:vgg16}{{9}{27}{structure of the VGG 16 deep convolutional network\relax }{figure.caption.62}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.4.5.2}Inception V2}{27}{paragraph.63}}
\newlabel{para:inception_v2}{{2.4.5.2}{27}{Inception V2}{paragraph.63}{}}
\@writefile{brf}{\backcite{RefWorks:30}{{27}{2.4.5.2}{paragraph.63}}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The inception module with the concatenation of a pool, a $1 \times 1$, a $3 \times 3$ and a $5 \times 5$ convolution operations\relax }}{28}{figure.caption.64}}
\newlabel{fig:inception_module}{{10}{28}{The inception module with the concatenation of a pool, a $1 \times 1$, a $3 \times 3$ and a $5 \times 5$ convolution operations\relax }{figure.caption.64}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.6}Evaluation Measures}{28}{subsubsection.66}}
\newlabel{sec:measures}{{2.4.6}{28}{Evaluation Measures}{subsubsection.66}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The inception module with the concatenation of a pool, a $1 \times 1$, a $3 \times 3$ and a $5 \times 5$ convolution operations\relax }}{29}{figure.caption.65}}
\newlabel{fig:inception_v2_module}{{11}{29}{The inception module with the concatenation of a pool, a $1 \times 1$, a $3 \times 3$ and a $5 \times 5$ convolution operations\relax }{figure.caption.65}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.4.6.1}True/False Positives and Negatives}{29}{paragraph.67}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces The four categories a model's prediction can fall in\relax }}{30}{figure.caption.68}}
\newlabel{fig:tf_pos_neg}{{12}{30}{The four categories a model's prediction can fall in\relax }{figure.caption.68}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.4.6.2}Accuracy}{30}{paragraph.69}}
\newlabel{para:accuracy}{{2.4.6.2}{30}{Accuracy}{paragraph.69}{}}
\newlabel{eq:accuracy}{{17}{30}{Accuracy}{equation.70}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.4.6.3}Partial Accuracy}{30}{paragraph.71}}
\newlabel{para:partial_accuracy}{{2.4.6.3}{30}{Partial Accuracy}{paragraph.71}{}}
\newlabel{eq:partial_accuracy}{{18}{31}{Partial Accuracy}{equation.72}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.4.6.4}Recall}{31}{paragraph.73}}
\newlabel{para:recall}{{2.4.6.4}{31}{Recall}{paragraph.73}{}}
\newlabel{eq:recall}{{19}{31}{Recall}{equation.74}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.4.6.5}Precision}{31}{paragraph.75}}
\newlabel{para:precision}{{2.4.6.5}{31}{Precision}{paragraph.75}{}}
\newlabel{eq:precision}{{20}{31}{Precision}{equation.76}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.4.6.6}F1 Measure}{31}{paragraph.77}}
\newlabel{para:f1_measure}{{2.4.6.6}{31}{F1 Measure}{paragraph.77}{}}
\newlabel{eq:F1}{{21}{32}{F1 Measure}{equation.78}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}EmotioNet Database}{33}{section.79}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Downloading}{33}{subsection.80}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Reading the xlsx file}{33}{subsubsection.81}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Downloading the image}{33}{subsubsection.82}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}Storing the image}{34}{subsubsection.83}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Converting to TFRecords}{35}{subsection.84}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Extending TF-Slim datasets}{36}{subsection.85}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Annotating Valence and Arousal}{36}{subsection.86}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Action Unit Prediction}{37}{section.87}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Adapting training scripts}{37}{subsection.88}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Duplicating the Logits}{37}{subsubsection.89}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Cleaning the Labels}{38}{subsubsection.90}}
\newlabel{sec:cleaning}{{4.1.2}{38}{Cleaning the Labels}{subsubsection.90}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}Changing the final activation function}{38}{subsubsection.91}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Prediction of 60 Action Units}{39}{subsection.92}}
\newlabel{sec:pred_60_au}{{4.2}{39}{Prediction of 60 Action Units}{subsection.92}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Fine-tuning}{39}{subsubsection.93}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Evaluation}{39}{subsubsection.94}}
\newlabel{sec:eval_60_au}{{4.2.2}{39}{Evaluation}{subsubsection.94}{}}
\citation{RefWorks:17}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Evaluation measures for AU prediction/classification on the full set of AUs (AUs 1 to 60)\relax }}{40}{table.caption.95}}
\newlabel{tab:eval_au_60}{{3}{40}{Evaluation measures for AU prediction/classification on the full set of AUs (AUs 1 to 60)\relax }{table.caption.95}{}}
\@writefile{brf}{\backcite{RefWorks:17}{{40}{4.2.2}{table.caption.95}}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Reporting the number of True/False Positives/Negatives for VGG 16 and Inception V2 trained to predict action units for the full set of action units\relax }}{41}{table.caption.96}}
\newlabel{tab:tf_pos_neg_60_au}{{4}{41}{Reporting the number of True/False Positives/Negatives for VGG 16 and Inception V2 trained to predict action units for the full set of action units\relax }{table.caption.96}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Conclusion}{41}{subsubsection.97}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Predicting 11 Action Units}{41}{subsection.98}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Fine-tuning}{42}{subsubsection.110}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.3.1.1}Batch Size Selection}{43}{paragraph.111}}
\newlabel{para:batch_size_au11}{{4.3.1.1}{43}{Batch Size Selection}{paragraph.111}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {4.3.1.2}Initial Learning Rate Selection}{43}{paragraph.113}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Training loss for different batch sizes: 32=orange, 64=cyan, 128=magenta, 256=green\relax }}{44}{figure.caption.112}}
\newlabel{fig:batch_size_11au}{{13}{44}{Training loss for different batch sizes: 32=orange, 64=cyan, 128=magenta, 256=green\relax }{figure.caption.112}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Training loss using Inception V2 model with the following different initial learning rates: 0.1=purple, 0.01=cyan, 0.001=orange\relax }}{44}{figure.caption.114}}
\newlabel{fig:learning_rate_au11_inception}{{14}{44}{Training loss using Inception V2 model with the following different initial learning rates: 0.1=purple, 0.01=cyan, 0.001=orange\relax }{figure.caption.114}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Evaluation measures for AU prediction/classification on the restricted set 11 AUs\relax }}{45}{table.caption.117}}
\newlabel{tab:eval_au_11}{{5}{45}{Evaluation measures for AU prediction/classification on the restricted set 11 AUs\relax }{table.caption.117}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Evaluation}{45}{subsubsection.116}}
\newlabel{sec:eval_11_au}{{4.3.2}{45}{Evaluation}{subsubsection.116}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Conclusion}{45}{subsubsection.119}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Reporting the number of True/False Positives/Negatives for VGG 16 and Inception V2 trained to predict the restricted set of 11 action units\relax }}{46}{table.caption.118}}
\newlabel{tab:tf_pos_neg_11_au}{{6}{46}{Reporting the number of True/False Positives/Negatives for VGG 16 and Inception V2 trained to predict the restricted set of 11 action units\relax }{table.caption.118}{}}
\newlabel{fig:learning_rate_01_11au_vgg16}{{15a}{47}{$\alpha =0.1$\relax }{figure.caption.115}{}}
\newlabel{sub@fig:learning_rate_01_11au_vgg16}{{a}{47}{$\alpha =0.1$\relax }{figure.caption.115}{}}
\newlabel{fig:learning_rate_001_11au_vgg16}{{15b}{47}{$\alpha =0.01$\relax }{figure.caption.115}{}}
\newlabel{sub@fig:learning_rate_001_11au_vgg16}{{b}{47}{$\alpha =0.01$\relax }{figure.caption.115}{}}
\newlabel{fig:learning_rate_0001_11au_vgg16}{{15c}{47}{$\alpha = 0.001$\relax }{figure.caption.115}{}}
\newlabel{sub@fig:learning_rate_0001_11au_vgg16}{{c}{47}{$\alpha = 0.001$\relax }{figure.caption.115}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Training loss against number of steps for the VGG model for varying initial learning rate $\alpha $\relax }}{47}{figure.caption.115}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Valence and Arousal Regression}{48}{section.120}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Inception V2}{48}{subsection.121}}
\newlabel{sec:valar_inception_v2}{{5.1}{48}{Inception V2}{subsection.121}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Fine-tuning}{48}{subsubsection.122}}
\newlabel{sec:valar_fine}{{5.1.1}{48}{Fine-tuning}{subsubsection.122}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {5.1.1.1}Batch Size Selection}{48}{paragraph.123}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Training loss against number of steps for different batch sizes: 32=orange, 64=cyan, 128=magenta, 256=blue\relax }}{49}{figure.caption.124}}
\newlabel{fig:batch_size_valar_inception}{{16}{49}{Training loss against number of steps for different batch sizes: 32=orange, 64=cyan, 128=magenta, 256=blue\relax }{figure.caption.124}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Evaluation}{49}{subsubsection.125}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Future Work}{51}{section.130}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Valence and Arousal Regression}{51}{subsection.131}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1}Larger Dataset}{51}{subsubsection.132}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.2}More Models and Full Training}{51}{subsubsection.137}}
\citation{RefWorks:6}
\citation{RefWorks:6}
\citation{RefWorks:6}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Video Analysis}{52}{subsection.138}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1}Recurrent Neural Networks}{52}{subsubsection.139}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.2}3D Convolutional Network}{52}{subsubsection.140}}
\@writefile{brf}{\backcite{RefWorks:6}{{52}{6.2.2}{subsubsection.140}}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Example of a 3D convolution, note that connections with the same colours share the same weights\relax }}{53}{figure.caption.141}}
\@writefile{brf}{\backcite{RefWorks:6}{{53}{17}{figure.caption.141}}}
\newlabel{fig:3d_conv}{{17}{53}{Example of a 3D convolution, note that connections with the same colours share the same weights\relax }{figure.caption.141}{}}
\bibstyle{plain}
\bibdata{refs.bib}
\bibcite{RefWorks:1}{{1}{}{{}}{{}}}
\bibcite{RefWorks:26}{{2}{}{{}}{{}}}
\bibcite{RefWorks:12}{{3}{}{{}}{{}}}
\bibcite{RefWorks:10}{{4}{}{{}}{{}}}
\bibcite{RefWorks:28}{{5}{}{{}}{{}}}
\bibcite{RefWorks:6}{{6}{}{{}}{{}}}
\bibcite{RefWorks:30}{{7}{}{{}}{{}}}
\bibcite{RefWorks:25}{{8}{}{{}}{{}}}
\bibcite{RefWorks:17}{{9}{}{{}}{{}}}
\bibcite{RefWorks:18}{{10}{}{{}}{{}}}
\bibcite{RefWorks:24}{{11}{}{{}}{{}}}
\bibcite{RefWorks:19}{{12}{}{{}}{{}}}
\bibcite{RefWorks:13}{{13}{}{{}}{{}}}
\bibcite{RefWorks:22}{{14}{}{{}}{{}}}
\bibcite{RefWorks:23}{{15}{}{{}}{{}}}
\bibcite{RefWorks:2}{{16}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers

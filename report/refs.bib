


@inproceedings{RefWorks:3,
	author={Yoshua Bengio},
	year={2013},
	title={Deep learning of representations: Looking forward},
	booktitle={International Conference on Statistical Language and Speech Processing},
	publisher={Springer},
	pages={1-37}
}
@article{RefWorks:5,
	author={Yoshua Bengio},
	year={2012},
	title={Deep Learning of Representations for Unsupervised and Transfer Learning.},
	journal={ICML Unsupervised and Transfer Learning},
	volume={27},
	pages={17-36}
}
@article{RefWorks:9,
	author={Ira Cohen and Nicu Sebe and Ashutosh Garg and Lawrence S. Chen and Thomas S. Huang},
	year={2003},
	month={0},
	title={Facial expression recognition from video sequences: temporal and static modeling},
	journal={Computer Vision and Image Understanding},
	volume={91},
	number={1–2},
	pages={160-187},
	abstract={The most expressive way humans display emotions is through facial expressions. In this work we report on several advances we have made in building a system for classification of facial expressions from continuous video input. We introduce and test different Bayesian network classifiers for classifying expressions from video, focusing on changes in distribution assumptions, and feature dependency structures. In particular we use Naive–Bayes classifiers and change the distribution from Gaussian to Cauchy, and use Gaussian Tree-Augmented Naive Bayes (TAN) classifiers to learn the dependencies among different facial motion features. We also introduce a facial expression recognition from live video input using temporal cues. We exploit the existing methods and propose a new architecture of hidden Markov models (HMMs) for automatically segmenting and recognizing human facial expression from video sequences. The architecture performs both segmentation and recognition of the facial expressions automatically using a multi-level architecture composed of an HMM layer and a Markov model layer. We explore both person-dependent and person-independent recognition of expressions and compare the different methods.},
	isbn={1077-3142},
	doi={http://dx.doi.org/10.1016/S1077-3142(03)00081-X}
}
@article{RefWorks:12,
	author={Paul Ekman and Wallace V. Friesen},
	year={1971},
	title={Constants across cultures in the face and emotion.},
	journal={Journal of personality and social psychology},
	volume={17},
	number={2},
	pages={124}
}
@article{RefWorks:10,
	author={Paul Ekman and Wallace V. Friesen and Joseph C. Hager},
	year={1978},
	title={Facial action coding system (FACS)},
	journal={A technique for the measurement of facial action.Consulting, Palo Alto},
	volume={22}
}
@inproceedings{RefWorks:1,
	author={C. Fabian Benitez-Quiroz and Ramprakash Srinivasan and Aleix M. Martinez},
	year={2016},
	title={EmotioNet: An accurate, real-time algorithm for the automatic annotation of a million facial expressions in the wild},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={5562-5570}
}
@article{RefWorks:20,
	author={Beat Fasel and Juergen Luettin},
	year={2003},
	title={Automatic facial expression analysis: a survey},
	journal={Pattern Recognition},
	volume={36},
	number={1},
	pages={259-275}
}
@article{RefWorks:11,
	author={B. Fasel and Juergen Luettin},
	year={2003},
	month={1},
	title={Automatic facial expression analysis: a survey},
	journal={Pattern Recognition},
	volume={36},
	number={1},
	pages={259-275},
	abstract={Over the last decade, automatic facial expression analysis has become an active research area that finds potential applications in areas such as more engaging human–computer interfaces, talking heads, image retrieval and human emotion analysis. Facial expressions reflect not only emotions, but other mental activities, social interaction and physiological signals. In this survey, we introduce the most prominent automatic facial expression analysis methods and systems presented in the literature. Facial motion and deformation extraction approaches as well as classification methods are discussed with respect to issues such as face normalization, facial expression dynamics and facial expression intensity, but also with regard to their robustness towards environmental changes.},
	keywords={Facial expression recognition; Facial expression interpretation; Emotion recognition; Affect recognition; FACS},
	isbn={0031-3203},
	doi={http://dx.doi.org/10.1016/S0031-3203(02)00052-3}
}
@inproceedings{RefWorks:14,
	author={Ian J. Goodfellow and Dumitru Erhan and Pierre Luc Carrier and Aaron Courville and Mehdi Mirza and Ben Hamner and Will Cukierski and Yichuan Tang and David Thaler and Dong-Hyun Lee},
	year={2013},
	title={Challenges in representation learning: A report on three machine learning contests},
	booktitle={International Conference on Neural Information Processing},
	publisher={Springer},
	pages={117-124}
}
@article{RefWorks:4,
	author={Geoffrey E. Hinton},
	year={2007},
	title={Learning multiple layers of representation},
	journal={Trends in cognitive sciences},
	volume={11},
	number={10},
	pages={428-434}
}
@article{RefWorks:6,
	author={Shuiwang Ji and Wei Xu and Ming Yang and Kai Yu},
	year={2013},
	title={3D convolutional neural networks for human action recognition},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={35},
	number={1},
	pages={221-231}
}
@article{RefWorks:17,
	author={S. Mohammad Mavadati and Mohammad H. Mahoor and Kevin Bartlett and Philip Trinh and Jeffrey F. Cohn},
	year={2013},
	title={Disfa: A spontaneous facial action intensity database},
	journal={IEEE Transactions on Affective Computing},
	volume={4},
	number={2},
	pages={151-160}
}
@inproceedings{RefWorks:18,
	author={Daniel McDuff and Rana Kaliouby and Thibaud Senechal and May Amr and Jeffrey Cohn and Rosalind Picard},
	year={2013},
	title={Affectiva-mit facial expression dataset (am-fed): Naturalistic and spontaneous facial expressions collected},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
	pages={881-888}
}
@article{RefWorks:19,
	author={Maja Pantic and Leon J. M. Rothkrantz},
	year={2000},
	title={Automatic analysis of facial expressions: The state of the art},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={22},
	number={12},
	pages={1424-1445}
}
@book{RefWorks:13,
	author={RL Schiefelbusch},
	year={1982},
	title={Handbook of methods in nonverbal behavior research. Klaus R. Scherer \& Paul Ekman (Eds.). Cambridge University Press, 1982.},
	publisher={Cambridge Univ Press},
	volume={4},
	number={03}
}
@article{RefWorks:21,
	author={Karen Simonyan and Andrew Zisserman},
	year={2014},
	title={Very Deep Convolutional Networks for Large-Scale Image Recognition},
	journal={CoRR},
	volume={abs/1409.1556},
	url={http://arxiv.org/abs/1409.1556}
}
@inproceedings{RefWorks:15,
	author={Christian Szegedy and Wei Liu and Yangqing Jia and Pierre Sermanet and Scott Reed and Dragomir Anguelov and Dumitru Erhan and Vincent Vanhoucke and Andrew Rabinovich},
	year={2015},
	title={Going deeper with convolutions},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={1-9}
}
@inproceedings{RefWorks:2,
	author={Stefanos Zafeiriou and Athanasios Papaioannou and Irene Kotsia and Mihalis A. Nicolaou and Guoying Zhao and E. Antonakos and P. Snape and G. Trigeorgis and S. Zafeiriou},
	title={Facial Affect “in-the-wild”: A survey and a new database},
	booktitle={International Conference on Computer Vision}
}
